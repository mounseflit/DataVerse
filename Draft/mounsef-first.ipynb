{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGeVDaCMbqGY"
   },
   "source": [
    "# Hello Ensa Khouribga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\python312\\lib\\site-packages (1.26.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (3.8.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\python312\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python312\\lib\\site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\python312\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python312\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\python312\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeoPrthmakjd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFB672sNa3HK"
   },
   "source": [
    "**0. Configures basic logging:**\n",
    "\n",
    "sets up the logging system to track events and potential issues during the execution of your script. It's important to note that the line is repeated twice, which is redundant and one instance should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKmKrofEa3n6"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwhVlj-0a7wP"
   },
   "source": [
    "**1. Data Loading (load_data function):**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19YT5DmRa8JE"
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        logging.info(f\"Successfully loaded {file_path}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSnaLckNa_4A"
   },
   "source": [
    "**2. Data Preprocessing (preprocess_data function):**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJK1hojVbAGI"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess Data\n",
    "def preprocess_data(df):\n",
    "    df.ffill(inplace=True)\n",
    "\n",
    "    # One-hot encode categorical features\n",
    "    categorical_features = ['SchoolDepartment', 'CourseTitle', 'RequiredSkill', 'GainedSkill']\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    encoded_features = encoder.fit_transform(df[categorical_features])\n",
    "\n",
    "    # Scale numerical features\n",
    "    if 'Hour' in df.columns:\n",
    "        df['Hour'] = pd.to_datetime(df['Hour'], errors='coerce').dt.hour.fillna(0).astype(float)\n",
    "    else:\n",
    "        logging.warning(\"Column 'Hour' does not exist.\")\n",
    "        df['Hour'] = 0\n",
    "    scaler = StandardScaler()\n",
    "    numeric_features = scaler.fit_transform(df[['Hour']])\n",
    "\n",
    "    # Combine features\n",
    "    features = np.hstack((encoded_features, numeric_features))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buJTW8q8uhkq"
   },
   "source": [
    "**3. Apply PCA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2C3VtYlLukJc"
   },
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "def apply_pca(features, n_components=2):\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    reduced_features = pca.fit_transform(features)\n",
    "    logging.info(f\"PCA reduced features to {n_components} dimensions.\")\n",
    "    return reduced_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXpVnjEwbKdD"
   },
   "source": [
    "**4. Evaluate clustering:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZ1LBwzzbK9U"
   },
   "outputs": [],
   "source": [
    "# Evaluate Clustering\n",
    "def evaluate_clustering(features, clusters):\n",
    "    if len(set(clusters)) > 1:\n",
    "        sil_score = silhouette_score(features, clusters)\n",
    "        calinski_harabasz = calinski_harabasz_score(features, clusters)\n",
    "        davies_bouldin = davies_bouldin_score(features, clusters)\n",
    "        return sil_score, calinski_harabasz, davies_bouldin\n",
    "    else:\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTshvo1XbRXP"
   },
   "source": [
    "**5. Visualize:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBq54AcUbR_o"
   },
   "outputs": [],
   "source": [
    "# Visualize Clusters\n",
    "def visualize_clusters(features, clusters, title):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(features[:, 0], features[:, 1], c=clusters, cmap='viridis', s=30, alpha=0.7)\n",
    "    plt.title(f\"Cluster Visualization - {title}\")\n",
    "    plt.xlabel(\"PCA Component 1\")\n",
    "    plt.ylabel(\"PCA Component 2\")\n",
    "    plt.colorbar(label='Cluster')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7y2nvRSbb8I"
   },
   "source": [
    "**6. Training and evaluation:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FzqGeZbnbcdU"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train and Evaluate Models\n",
    "def train_and_evaluate_models(features):\n",
    "    results = []\n",
    "\n",
    "    # KMeans\n",
    "    kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "    kmeans_clusters = kmeans.fit_predict(features)\n",
    "    kmeans_scores = evaluate_clustering(features, kmeans_clusters)\n",
    "    if kmeans_scores[0] is not None:\n",
    "        results.append(['KMeans'] + list(kmeans_scores))\n",
    "        visualize_clusters(features, kmeans_clusters, \"KMeans\")\n",
    "\n",
    "    # Agglomerative Clustering\n",
    "    agg = AgglomerativeClustering(n_clusters=4)\n",
    "    agg_clusters = agg.fit_predict(features)\n",
    "    agg_scores = evaluate_clustering(features, agg_clusters)\n",
    "    if agg_scores[0] is not None:\n",
    "        results.append(['AgglomerativeClustering'] + list(agg_scores))\n",
    "        visualize_clusters(features, agg_clusters, \"Agglomerative Clustering\")\n",
    "\n",
    "    # DBSCAN\n",
    "    dbscan = DBSCAN(eps=0.4, min_samples=5)\n",
    "    dbscan_clusters = dbscan.fit_predict(features)\n",
    "    dbscan_scores = evaluate_clustering(features, dbscan_clusters)\n",
    "    if dbscan_scores[0] is not None:\n",
    "        results.append(['DBSCAN'] + list(dbscan_scores))\n",
    "        visualize_clusters(features, dbscan_clusters, \"DBSCAN\")\n",
    "\n",
    "    # Gaussian Mixture\n",
    "    gmm = GaussianMixture(n_components=4, random_state=42)\n",
    "    gmm_clusters = gmm.fit_predict(features)\n",
    "    gmm_scores = evaluate_clustering(features, gmm_clusters)\n",
    "    if gmm_scores[0] is not None:\n",
    "        results.append(['GaussianMixture'] + list(gmm_scores))\n",
    "        visualize_clusters(features, gmm_clusters, \"Gaussian Mixture\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8aKPcQjboD6"
   },
   "source": [
    "**8. Main Execution (main function):**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-T0aq8Cboc6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 20:30:40,555 - ERROR - Error loading data/academic.csv: [Errno 2] No such file or directory: 'data/academic.csv'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['SchoolDepartment', 'CourseTitle', 'RequiredSkill', 'GainedSkill'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(results_df)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Load and preprocess data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     academic_df \u001b[38;5;241m=\u001b[39m load_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/academic.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43macademic_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Apply PCA for dimensionality reduction\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     reduced_features \u001b[38;5;241m=\u001b[39m apply_pca(features, n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      6\u001b[0m categorical_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSchoolDepartment\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCourseTitle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRequiredSkill\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGainedSkill\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(sparse_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m encoded_features \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Scale numerical features\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHour\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['SchoolDepartment', 'CourseTitle', 'RequiredSkill', 'GainedSkill'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Main Function\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    academic_df = load_data('Notebooks/data/academic.csv')\n",
    "    features = preprocess_data(academic_df)\n",
    "\n",
    "    # Apply PCA for dimensionality reduction\n",
    "    reduced_features = apply_pca(features, n_components=2)\n",
    "\n",
    "    # Train and evaluate clustering algorithms\n",
    "    results = train_and_evaluate_models(reduced_features)\n",
    "\n",
    "    # Display results\n",
    "    columns = ['Algorithm', 'Silhouette Score', 'Calinski-Harabasz Index', 'Davies-Bouldin Index']\n",
    "    results_df = pd.DataFrame(results, columns=columns)\n",
    "    print(results_df)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
